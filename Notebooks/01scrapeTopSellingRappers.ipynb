{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a7d19e-0195-42f4-8201-782959bb84c0",
   "metadata": {},
   "source": [
    "# Regional Analysis of Rapper Influences - Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727a4c9-7e63-4afb-aa0b-d051887f7f8d",
   "metadata": {},
   "source": [
    "Inspired by my trip to Atlanta, this project aims to analyze regional upbringings and influence of the top selling rappers over the last few decades. While there is no readily available and complete dataset for the top selling rap artists, there are webpages that list off the top selling artists of that year. In this script, I will scrape through many webpages to collect the artists with the biggest first week album sales of that year. In essence, I aim to get a rough sample of the highest paying rappers over time. Then, data cleaning is conducted to clean the list into a readable and useable format for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "3e1a8ac7-9f0c-47dd-b593-4413241b2ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d504d-664f-4d01-8674-e445e9080fc3",
   "metadata": {},
   "source": [
    "## Web Scrape the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "33793f79-a21e-4d8d-8ebc-c44f1a420168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace 'your_url_pattern' and 'your_element_selector' with actual values\n",
    "base_url = 'https://beats-rhymes-lists.com/sales/biggest-hip-hop-album-first-week-sales-of-'\n",
    "page_range = range(1998, 2024)  # Adjust the range based on the pages you want to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "363ac383-6f72-4e64-ab93-8572e001d323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the page. Status code: 200\n"
     ]
    }
   ],
   "source": [
    "scraped_df = pd.DataFrame(columns=['Top Artists', 'Year'])\n",
    "\n",
    "for page_number in page_range:\n",
    "    url = f'{base_url}{page_number}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Use the CSS selector for <h2> with class 'wp-block-heading' containing <em>\n",
    "        target_elements = soup.select('h2')\n",
    "\n",
    "        # Create a Pandas DataFrame\n",
    "        tmp = pd.DataFrame(columns=['Top Artists', 'Year'])\n",
    "\n",
    "    for element in target_elements:\n",
    "        # Process or print the extracted text\n",
    "        extracted_text = element.text.strip()\n",
    "        tmp1 = {'Top Artists': extracted_text, 'Year': page_number}\n",
    "\n",
    "        # Append the extracted text to the DataFrame\n",
    "        tmp = pd.concat([tmp, pd.DataFrame([tmp1])], ignore_index=True)\n",
    "        \n",
    "    scraped_df = pd.concat([scraped_df, tmp], ignore_index=True)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c24bb9-9a06-4344-83a5-f557fcc1dda3",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "46604725-ca4e-498e-a289-8ae44aa67168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_values = ['All Time', 'Album Sales', 'First Week Sales', 'Best-Selling', 'Most Number 1']\n",
    "scraped_df['Top Artists'] = scraped_df['Top Artists'].astype(str)\n",
    "scraped_df['Year'] = scraped_df['Year'].astype(int)\n",
    "scraped_df = scraped_df[~scraped_df['Top Artists'].str.contains('|'.join(drop_values))].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "efa0b342-8a89-4e85-b7be-3fed3102a54d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index                                        Top Artists  Year\n",
      "0        0    10.\\n \\n  It’s Dark and Hell Is Hot\\n \\n by DMX  1998\n",
      "1        1  9.\\n \\n  Charge It 2 Da Game\\n \\n Silkk by The...  1998\n",
      "2        2     8.\\n \\n  Vol. 2… Hard Knock Life\\n \\n by Jay-Z  1998\n",
      "3        3          7.\\n \\n  Ghetto Fabulous\\n \\n by Mystikal  1998\n",
      "4        4  6.\\n \\n  Tical 2000: Judgement Day\\n \\n by Met...  1998\n",
      "..     ...                                                ...   ...\n",
      "312    412  YoungBoy Never Broke Again –\\n \\n  I Rest My Case  2023\n",
      "313    413                Lil Yachty –\\n \\n  Let’s Start Here  2023\n",
      "314    414                      Don Toliver –\\n \\n  Love Sick  2023\n",
      "315    415                             Yeat –\\n \\n  Afterlyfe  2023\n",
      "316    416                 Trippie Redd –\\n \\n  Mansion Musik  2023\n",
      "\n",
      "[317 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "#     print(scraped_df)\n",
    "print(scraped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "e2664e99-c5b2-449d-8334-e38527786fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Top Artists  Year\n",
      "0                           DMX  1998\n",
      "1                   The Shocker  1998\n",
      "2                         Jay-Z  1998\n",
      "3                      Mystikal  1998\n",
      "4                    Method Man  1998\n",
      "..                          ...   ...\n",
      "315                        Yeat  2023\n",
      "312  YoungBoy Never Broke Again  2023\n",
      "313                  Lil Yachty  2023\n",
      "314                 Don Toliver  2023\n",
      "316                Trippie Redd  2023\n",
      "\n",
      "[317 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Dataframe 1\n",
    "clean_df1 = pd.DataFrame(columns=['Top Artists', 'Year'])\n",
    "\n",
    "for index, row in scraped_df.iterrows():\n",
    "    if 1998 <= scraped_df.iloc[index, 2] <= 2003 or 2011 <= scraped_df.iloc[index, 2] <= 2021:\n",
    "        substring = 'by '\n",
    "        parts = scraped_df.iloc[index, 1].split(substring, 1) # Split substring with 'by ' as separator\n",
    "        clean_tmp1 = {'Top Artists': parts[1].strip(), 'Year': scraped_df.iloc[index, 2]} # Add substring to dict w/ Year\n",
    "        clean_df1 = pd.concat([clean_df1, pd.DataFrame([clean_tmp1])], ignore_index=True) # Append to datafrane\n",
    "\n",
    "# Dataset 2\n",
    "scraped_tmp = scraped_df.copy()\n",
    "\n",
    "def extract_artist1(entry):\n",
    "    match = re.search(r'^(.*?)( –\\n|\\n)', entry) # Search for all characters before '–\\n' or '\\n'\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the extraction function only when 'Year' is in [2022, 2023]\n",
    "condition = scraped_tmp['Year'].isin([2022, 2023]) \n",
    "scraped_tmp.loc[condition, 'Top Artists'] = scraped_tmp.loc[condition, 'Top Artists'].apply(extract_artist1) \n",
    "\n",
    "# Select the relevant columns\n",
    "clean_df2 = scraped_tmp.loc[condition, ['Top Artists', 'Year']]\n",
    "\n",
    "# Clean dataset 3\n",
    "scraped_tmp = scraped_df.copy()\n",
    "\n",
    "def extract_artist2(entry):\n",
    "    match = re.search(r'\\d+\\.\\s([^\\n]+)\\s–', entry)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the extraction function only when 'Year' is in 2004-2010\n",
    "condition = scraped_tmp['Year'].isin([2004, 2005, 2006, 2007, 2008, 2009, 2010])\n",
    "scraped_tmp.loc[condition, 'Top Artists'] = scraped_tmp.loc[condition, 'Top Artists'].apply(extract_artist2)\n",
    "\n",
    "# Select the relevant columns\n",
    "clean_df3 = scraped_tmp.loc[condition, ['Top Artists', 'Year']]\n",
    "\n",
    "# Merge dataframes\n",
    "full_df = pd.concat([clean_df1, clean_df3, clean_df2])\n",
    "full_df = full_df.sort_values(by=['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "96c0c9e6-d121-4036-a571-c0510e27bc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export DataFrame to CSV File\n",
    "full_df.to_csv('topSellingRappers_1998-2023.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
